\section{Related Work}
In the past years, several image colorization models were developed. They belong to three main categories:
scribble-based, example-based and deep learning models. Regarding the latter, a common approach was using
a CNN based on the VGG-16 architecture. Dahl's model, Zhang's models Eccv16 \cite{zhang} and Siggraph17 and the more recent InstColorization \cite{su} all belong to this category. Despite some
small changes in the models' architectures, the most important difference among those models consists in the loss
functions they use.

Other recent and successful deep learning approaches concern the employment of GANs, like in
ChromaGAN.
 
Another approach consists in using memory neural networks that are augmented with an external
memory module used to store some critical information. An example of this method is MemoPainter \cite{animation},
which combines a colorization network with a memory network to store rare instances, thus allowing the
colorization network to produce high-quality colorization with a limited amount of data.

Concerning the scribble-based approach, some models exploit user inputs to improve the colorization process.
That's the case of Siggraph17 with user local hints, and the LBIE model by \cite{language}, which
uses the image textual description provided by the user.

The aforementioned methods are just a few examples: there are many more approaches that we won't cover here.
