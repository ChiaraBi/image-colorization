\section{Related Work}
In the past years, several image colorization models were developed. They belong to three main cathegories: scribble-based, example-based and deep learning models. Reguarding the latter, a common approach was the use of a CNN based on the VGG-16 architecture. Dahl's model \cite{dahl}, Zhang's models Eccv16 \cite{zhang} and Siggraph17 \cite{siggraph} and the more recent InstColorization \cite{su} all belong to this cathegory. Despite of some
small changes in the models' architectures, the most important difference among those models consists in the loss
functions they use.

Other recent and successful deep learning approaches concern the employment of GANs, such as ChromaGAN \cite{chromagan}.
 
Another approach consists in using memory neural networks that are augmented with an external
memory module used to store some critical information. An example of this method is MemoPainter \cite{animation},
combining a colorization network with a memory network to store rare instances, thus allowing the
colorization network to produce high-quality colorization with a limited amount of data.

Concerning the scribble-based approach, some colorizers exploit user inputs to improve the colorization process. That's the case of
Siggraph17 \cite{siggraph} with user local hints, and the LBIE model by \cite{language}, which uses the image textual description provided by the user.

In conclusion, there are many more approaches that we won't cover here.
