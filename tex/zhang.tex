\subsection{Eccv16}
The innovation introduced by Zhang's colorization model is not the model's architecture (a CNN made of 8 blocks of
two or three repeated Convolutional and ReLU layers followed by a BatchNorm layer, as shown in Figure \ref{fig:zh}) but rather a more suitable loss function for saturated colorization, combined with class rebalancing, which allows to increase the diversity of colors in the results.

Since an object can potentially have several plausible colorization, the model accounts for the multimodal
distribution of possible colors for each pixel. Indeed, the intrinsic multimodal nature of the colorization
problem can't be captured by a simple Euclidean loss between the target and the predicted colors. Instead, the
model learns a map $\mathcal{G}: \mathbb{R}^{H\times W\times1}\rightarrow [0,1]^{H\times W\times Q}$ from the grayscale input to a probability
distribution $\hat{Z}=P(a,b)$ over $Q=313$ possible $(a,b)$ pairs (i.e. colors), which were obtained throug the
quantization of the \textit{ab} output space, as shown in Figure \ref{fig:q}. Then, the multimomial crossentropy
los is defined as:

\begin{equation*}
	\mathcal{L}_{cl} (\hat{Z},Z)= - \sum_{h,w} v(Z_{h,w})\sum_q Z_{h,w,q}log(\hat{Z}_{h,w,q})
\end{equation*}
where $Z$ is the soft-encoded target (obtained by taking the 5-nearest neighbors in the quantized \textit{ab} space
for each groundtruth pixel, and weighting them according to their distance from the groundtruth) and $v$ is a
weighting function for class rebalancing, in order to emphasize rare colors.

To conclude, the final predicted colorization $\hat{Y}$ is the annealed-mean of the distribution $\hat{Z}$, which
consists in taking the mean of the softmax distribution $\sigma_T(\hat{Z}) = \sigma(\hat{Z}/T)$ adjusted according the
temperature parameter T. This avoids desaturated or spatially inconsistent results.