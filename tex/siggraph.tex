\subsection{Siggraph17}

This other Zhang's model is an interactive method that is trained on grayscale images integrated by concatenation
with some sparse user inputs. Then, the model can be tested in its automatic colorization version.

The model has a U-Net architecture $\mathcal{F}_\theta$ made of 10 convolutional blocks, each followed by a BatchNorm layer (Figure \ref{fig:si} in blue).
Symmetric shortcuts are added to upsampling Convolution layers and make it easier for deeper layers to access to important low-level information. Note that the subnetwork consisting of the first 8
convolutional blocks without shortcut connections, corresponds to the Eccv16 architecture.

The Local Hints Network (Figure \ref{fig:si} in red) incorporates the user points $U_l$ and predicts (as a side task, for user recommendation) a color distribution $\hat{Z}$. The Global Hints Network (Figure \ref{fig:si} in green) transforms the global hint $U_g$ by $1\times1$ Convolutional layers, and adds the result into the main colorization network.

The network learns to minimize the following loss:
\begin{equation*}
	\mathcal{L}_\delta(\mathcal{F}_\theta(X, U), Y) = \sum_{h,w} \sum_{q} \ell_\delta (\mathcal{F}_\theta(X, U)_{h,w,q}, Y_{h,w,q})
\end{equation*}
where $Y$ and $X$ are the groundtruth image and its greyscale version, $\mathcal{F}_\theta(X, U)$ is the network output based on the trainable weights $\theta$ and the user local or global hint $U$, and $\ell_\delta$ is a smooth-$\ell_1$ loss that doesn't consider the vibrant but artifact-prone colorization with class-rebalancing.

