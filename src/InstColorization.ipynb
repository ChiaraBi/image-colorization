{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InstColorization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4b3a2c52cccd42ac9d242f18a3211b65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1c9dd8b1c57945078b407144a6b72637","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5570472206d24cf9b2e1c15989ea7b0b","IPY_MODEL_a0021c1e48ef4476bba012b62bb1c526","IPY_MODEL_da33fb988eb542ca9af87eec0c1ac7ef"]}},"1c9dd8b1c57945078b407144a6b72637":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5570472206d24cf9b2e1c15989ea7b0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c15747f9cf384212807daeddf9825a2e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06cc26a877824039835f344c3cb76518"}},"a0021c1e48ef4476bba012b62bb1c526":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_98281c0b2b3441d09fe0502e7c9a9174","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":518,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_562160ad530a43b0a131e9f7119e66e5"}},"da33fb988eb542ca9af87eec0c1ac7ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_258805083c1e43c7b0fa14bea9d41cfc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/518 [00:11&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8108fd36ef5d4004848af35d3b997a36"}},"c15747f9cf384212807daeddf9825a2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"06cc26a877824039835f344c3cb76518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98281c0b2b3441d09fe0502e7c9a9174":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"562160ad530a43b0a131e9f7119e66e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"258805083c1e43c7b0fa14bea9d41cfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8108fd36ef5d4004848af35d3b997a36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"KnMeI8ow1203"},"source":["## Environment Setting"]},{"cell_type":"code","metadata":{"id":"xccN7_1QU-ac","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047645642,"user_tz":-120,"elapsed":148101,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"aab251d3-6faa-4401-bc03-ca902dcae6c7"},"source":["!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n","!pip install cython pyyaml==5.1\n","!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","!pip install dominate==2.4.0\n","!pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/cu101/torch_stable.html\n","Collecting torch==1.5\n","  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (703.8 MB)\n","\u001b[K     |████████████████████████████████| 703.8 MB 22 kB/s \n","\u001b[?25hCollecting torchvision==0.6\n","  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 26.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5) (0.16.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6) (7.1.2)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.5.0+cu101 which is incompatible.\u001b[0m\n","Successfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n","Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[K     |████████████████████████████████| 274 kB 5.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=f63b9d2f5a214f366b6a017b4c5f72fdb074389be43bdaefd868edf6b206a62d\n","  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-3opzv6_f\n","  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-3opzv6_f\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263932 sha256=029aaae0a0d97fdab2c31b9a6a9847072a7e6848db91b920c4bc8790c6c9319d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2h0187ab/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.2\n","    Uninstalling pycocotools-2.0.2:\n","      Successfully uninstalled pycocotools-2.0.2\n","Successfully installed pycocotools-2.0\n","Collecting dominate==2.4.0\n","  Downloading dominate-2.4.0-py2.py3-none-any.whl (29 kB)\n","Installing collected packages: dominate\n","Successfully installed dominate-2.4.0\n","Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\n","Collecting detectron2==0.1.2\n","  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/detectron2-0.1.2%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 642 kB/s \n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (7.1.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (0.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (0.8.9)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (1.1.0)\n","Collecting mock\n","  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (4.62.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (1.3.0)\n","Collecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting fvcore\n","  Downloading fvcore-0.1.5.post20210915.tar.gz (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (3.2.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (2.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.1.2) (1.3.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs>=0.1.6->detectron2==0.1.2) (5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->detectron2==0.1.2) (1.19.5)\n","Collecting iopath>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.2) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.2) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.2) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.1.2) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->detectron2==0.1.2) (1.15.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (0.6.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (3.17.3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (1.40.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (1.8.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (2.23.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (0.12.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (0.37.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (57.4.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.1.2) (3.3.4)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.2) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.1.2) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.2) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.2) (2021.5.30)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.2) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.2) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->detectron2==0.1.2) (3.7.4.3)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20210915-py3-none-any.whl size=60670 sha256=ed67c853af725899015125c64cd70c4f94a593470caf2c8e84ade0602f3eb95c\n","  Stored in directory: /root/.cache/pip/wheels/0e/e2/36/a659c9db2cf36699694e2651d1e458e88fb63b724c9458d3ab\n","Successfully built fvcore\n","Installing collected packages: portalocker, yacs, iopath, mock, fvcore, detectron2\n","Successfully installed detectron2-0.1.2+cu101 fvcore-0.1.5.post20210915 iopath-0.1.9 mock-4.0.3 portalocker-2.3.2 yacs-0.1.8\n"]}]},{"cell_type":"markdown","metadata":{"id":"53YjTYjm1j58"},"source":["## Clone the file from Gihub"]},{"cell_type":"code","metadata":{"id":"UoxuluzJmbiC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047646370,"user_tz":-120,"elapsed":732,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"868821e9-230d-46cc-aec7-2bab3740545a"},"source":["!git clone https://github.com/ericsujw/InstColorization.git"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'InstColorization'...\n","remote: Enumerating objects: 211, done.\u001b[K\n","remote: Counting objects: 100% (34/34), done.\u001b[K\n","remote: Compressing objects: 100% (23/23), done.\u001b[K\n","remote: Total 211 (delta 15), reused 11 (delta 11), pack-reused 177\u001b[K\n","Receiving objects: 100% (211/211), 6.11 MiB | 32.58 MiB/s, done.\n","Resolving deltas: 100% (82/82), done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"L65jjMKVpfkH"},"source":["## Start Colorization"]},{"cell_type":"code","metadata":{"id":"lIzoQKQhdTIl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047646370,"user_tz":-120,"elapsed":7,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"4bf460d4-ef91-4247-8218-d12505e17621"},"source":["cd InstColorization/"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/InstColorization\n"]}]},{"cell_type":"markdown","metadata":{"id":"sO-tvByunH3G"},"source":["## Download the Model"]},{"cell_type":"code","metadata":{"id":"SRQme7UHnNMf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047662372,"user_tz":-120,"elapsed":16006,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"4dbf6514-c305-4b05-80dc-fb8ee93581f7"},"source":["!sh scripts/download_model.sh"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","Finish download.\n","Archive:  checkpoints.zip\n","   creating: checkpoints/coco_finetuned_mask_256_ffs/\n","  inflating: checkpoints/coco_finetuned_mask_256_ffs/latest_net_GComp.pth  \n","  inflating: checkpoints/coco_finetuned_mask_256_ffs/latest_net_G.pth  \n","  inflating: checkpoints/coco_finetuned_mask_256_ffs/latest_net_GF.pth  \n","   creating: checkpoints/coco_finetuned_mask_256/\n","  inflating: checkpoints/coco_finetuned_mask_256/latest_net_GComp.pth  \n","  inflating: checkpoints/coco_finetuned_mask_256/latest_net_G.pth  \n","  inflating: checkpoints/coco_finetuned_mask_256/latest_net_GF.pth  \n","   creating: checkpoints/siggraph_retrained/\n","  inflating: checkpoints/siggraph_retrained/latest_net_G.pth  \n"]}]},{"cell_type":"markdown","metadata":{"id":"92YnbNtU2cdx"},"source":["### Detect Object bounding box\n"]},{"cell_type":"markdown","metadata":{"id":"3Z8V8s3f3cs0"},"source":["Setting the Detectron2."]},{"cell_type":"code","metadata":{"id":"ngV-n2MbvvTZ"},"source":["from os.path import join, isfile, isdir\n","from os import listdir\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","from argparse import ArgumentParser\n","\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","import numpy as np\n","import cv2\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","\n","import torch\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HUfLSSQf32SJ"},"source":["Let's create a bounding box folder to save our prediction results."]},{"cell_type":"code","metadata":{"id":"_XkvrdPgqP1e","executionInfo":{"status":"aborted","timestamp":1632047670056,"user_tz":-120,"elapsed":5,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}}},"source":["cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ftWuY5-6u9M"},"source":["!unzip mancanti.zip\n","#scambiare cartella test con cartella example"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5x7_BncXqqKT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047005857,"user_tz":-120,"elapsed":237,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"01dc1265-b4fa-4cfb-e6b2-3944b18c8e6a"},"source":["cd InstColorization"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/InstColorization\n"]}]},{"cell_type":"code","metadata":{"id":"Y5RSCOwA4Cum","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047043573,"user_tz":-120,"elapsed":293,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"3111d371-efeb-4be1-f493-3204a12f8699"},"source":["input_dir = \"example\"\n","image_list = [f for f in listdir(input_dir) if isfile(join(input_dir, f))]\n","output_npz_dir = \"{0}_bbox\".format(input_dir)\n","if os.path.isdir(output_npz_dir) is False:\n","    print('Create path: {0}'.format(output_npz_dir))\n","    os.makedirs(output_npz_dir)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Create path: example_bbox\n"]}]},{"cell_type":"markdown","metadata":{"id":"hBlhTIoA4YSB"},"source":["Here we simply take L channel as our input and make sure that we can get consistent box prediction results even though the original image is color images."]},{"cell_type":"code","metadata":{"id":"60Z0uIQH4ztv","executionInfo":{"status":"ok","timestamp":1632047415732,"user_tz":-120,"elapsed":369476,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}}},"source":["for image_path in image_list:\n","    img = cv2.imread(join(input_dir, image_path))\n","    lab_image = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n","    l_channel, a_channel, b_channel = cv2.split(lab_image)\n","    l_stack = np.stack([l_channel, l_channel, l_channel], axis=2)\n","    outputs = predictor(l_stack)\n","    save_path = join(output_npz_dir, image_path.split('.')[0])\n","    pred_bbox = outputs[\"instances\"].pred_boxes.to(torch.device('cpu')).tensor.numpy()\n","    pred_scores = outputs[\"instances\"].scores.cpu().data.numpy()\n","    np.savez(save_path, bbox = pred_bbox, scores = pred_scores)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Z4y8giu48hV"},"source":["Now we have all the images' prediction results."]},{"cell_type":"markdown","metadata":{"id":"fYvWpoUl5VKX"},"source":["### Colorize Images"]},{"cell_type":"markdown","metadata":{"id":"_0qhXEQ45bxc"},"source":["We first set up some libraries and options"]},{"cell_type":"code","metadata":{"id":"g80xLXzi9tOB","executionInfo":{"status":"ok","timestamp":1632047416105,"user_tz":-120,"elapsed":377,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}}},"source":["import sys\n","import time\n","from options.train_options import TestOptions\n","from models import create_model\n","\n","import torch\n","from tqdm import tqdm_notebook\n","\n","from fusion_dataset import Fusion_Testing_Dataset\n","from util import util\n","import multiprocessing\n","multiprocessing.set_start_method('spawn', True)\n","\n","torch.backends.cudnn.benchmark = True\n","\n","sys.argv = [sys.argv[0]]\n","opt = TestOptions().parse()"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xsMYnRQeKQEw"},"source":["Then we need to create a results folder to save our predicted color images and read the dataset loader."]},{"cell_type":"code","metadata":{"id":"KTWCeb2iEWFM","cellView":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047432052,"user_tz":-120,"elapsed":256,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"82bf1f71-babb-4c71-d655-d0a6fdab2779"},"source":["save_img_path = opt.results_img_dir\n","if os.path.isdir(save_img_path) is False:\n","    print('Create path: {0}'.format(save_img_path))\n","    os.makedirs(save_img_path)\n","opt.batch_size = 1\n","dataset = Fusion_Testing_Dataset(opt, -1)\n","dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=opt.batch_size)\n","\n","dataset_size = len(dataset)\n","print('#Testing images = %d' % dataset_size)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Create path: results\n","#Testing images = 518\n"]}]},{"cell_type":"markdown","metadata":{"id":"6aBEbi-vKgLG"},"source":["Load the pre-trained model."]},{"cell_type":"code","metadata":{"id":"kpw5UGUWImIq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632047437399,"user_tz":-120,"elapsed":1414,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"27e8c7a9-9194-4658-c6f5-49220ec2a852"},"source":["model = create_model(opt)\n","model.setup_to_test('coco_finetuned_mask_256_ffs')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["initialize network with normal\n","initialize network with normal\n","initialize network with normal\n","model [FusionModel] was created\n","load Fusion model from checkpoints/coco_finetuned_mask_256_ffs/latest_net_GF.pth\n"]}]},{"cell_type":"markdown","metadata":{"id":"vornjFjuKlzu"},"source":["Start to colorize every images in `dataset_loader`."]},{"cell_type":"code","metadata":{"id":"mwy1Tvh8Iuzm","colab":{"base_uri":"https://localhost:8080/","height":523,"referenced_widgets":["4b3a2c52cccd42ac9d242f18a3211b65","1c9dd8b1c57945078b407144a6b72637","5570472206d24cf9b2e1c15989ea7b0b","a0021c1e48ef4476bba012b62bb1c526","da33fb988eb542ca9af87eec0c1ac7ef","c15747f9cf384212807daeddf9825a2e","06cc26a877824039835f344c3cb76518","98281c0b2b3441d09fe0502e7c9a9174","562160ad530a43b0a131e9f7119e66e5","258805083c1e43c7b0fa14bea9d41cfc","8108fd36ef5d4004848af35d3b997a36"]},"executionInfo":{"status":"error","timestamp":1632047451964,"user_tz":-120,"elapsed":12241,"user":{"displayName":"Silvia Poletti","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13603842388162798275"}},"outputId":"1270c464-c5e0-40cb-db79-c27583007779"},"source":["count_empty = 0\n","for data_raw in tqdm_notebook(dataset_loader):\n","    data_raw['full_img'][0] = data_raw['full_img'][0].cuda()\n","    if data_raw['empty_box'][0] == 0:\n","        data_raw['cropped_img'][0] = data_raw['cropped_img'][0].cuda()\n","        box_info = data_raw['box_info'][0]\n","        box_info_2x = data_raw['box_info_2x'][0]\n","        box_info_4x = data_raw['box_info_4x'][0]\n","        box_info_8x = data_raw['box_info_8x'][0]\n","        cropped_data = util.get_colorization_data(data_raw['cropped_img'], opt, ab_thresh=0, p=opt.sample_p)\n","        full_img_data = util.get_colorization_data(data_raw['full_img'], opt, ab_thresh=0, p=opt.sample_p)\n","        model.set_input(cropped_data)\n","        model.set_fusion_input(full_img_data, [box_info, box_info_2x, box_info_4x, box_info_8x])\n","        model.forward()\n","    else:\n","        count_empty += 1\n","        full_img_data = util.get_colorization_data(data_raw['full_img'], opt, ab_thresh=0, p=opt.sample_p)\n","        model.set_forward_without_box(full_img_data)\n","    model.save_current_imgs(join(save_img_path, data_raw['file_id'][0] + '.png'))\n","print('{0} images without bounding boxes'.format(count_empty))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b3a2c52cccd42ac9d242f18a3211b65","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/518 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-70ac75ed2249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_fusion_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_img_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbox_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_info_2x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_info_4x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_info_8x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcount_empty\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/InstColorization/models/fusion_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhint_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetGF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_real_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_hint_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_mask_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_info_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_current_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/InstColorization/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_A, input_B, mask_B, instance_feature, box_info_list)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mconv10_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv10_up\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mconv10_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_layer10_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv10_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv10_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_info_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mout_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv10_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/InstColorization/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, instance_feature, bg_feature, box_info)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mfeatur_map_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatur_map_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mmask_list_maskout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_list_maskout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatur_map_list\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask_list_maskout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;31m# , instance_mask, torch.clamp(mask_list, 0.0, 1.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 672.00 MiB (GPU 0; 11.17 GiB total capacity; 9.66 GiB already allocated; 503.81 MiB free; 10.37 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"V_p79W3qt_QK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecc21ce2-af2b-46b5-fe53-7cb8123d7fd1"},"source":["cd InstColorization"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/InstColorization\n"]}]},{"cell_type":"code","metadata":{"id":"CeEF6KqPmzlT"},"source":["!zip -r results.zip results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lI2wv4qxuNRn"},"source":["from google.colab import files\n","files.download(\"results.zip\")  "],"execution_count":null,"outputs":[]}]}