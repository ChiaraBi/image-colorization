{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip test_cartoon.zip # cartoonized"
      ],
      "metadata": {
        "id": "EtnUG-mmb0PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test.zip    # original"
      ],
      "metadata": {
        "id": "DmS2QqxRQ184"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import io, color\n",
        "from os import listdir\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rfSlK4i7ZX-m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIRc7ullZQf-"
      },
      "outputs": [],
      "source": [
        "def define_model_baseline(img_h, img_w):\n",
        "\n",
        "    # encoder\n",
        "    inputs = Input(shape=(img_h, img_w, 3,))\n",
        "    encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(inputs)\n",
        "    encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "    encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    \n",
        "    # decoder\n",
        "    \n",
        "    decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "    decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "    decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = Conv2D(3, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "\n",
        "    # tie it together \n",
        "    model = Model(inputs=inputs, outputs=decoder_output)\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=define_model_baseline(256, 256)"
      ],
      "metadata": {
        "id": "cnWChrCjcXIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "_Atj32QCQu5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dir = '../content/cartoon/'\n",
        "\n",
        "Orig = []\n",
        "BW = []\n",
        "for filename in listdir(training_dir):\n",
        "  data_orig = img_to_array(load_img(training_dir+filename, target_size=(256,256)))\n",
        "  data_orig = 1.0/255*data_orig\n",
        "  data_BW = img_to_array(load_img(training_dir+filename, target_size=(256,256), color_mode='grayscale'))\n",
        "  data_BW = np.reshape(data_BW, newshape=(256,256))\n",
        "  data_BW_3 = np.zeros((256, 256, 3))\n",
        "  data_BW_3[:,:,0] = data_BW \n",
        "  data_BW_3[:,:,1] = data_BW\n",
        "  data_BW_3[:,:,2] = data_BW\n",
        "  data_BW_3 = 1.0/255*data_BW_3\n",
        "  Orig.append(data_orig)\n",
        "  BW.append(data_BW_3)\n",
        "  \n",
        "Orig = np.array(Orig)\n",
        "BW = np.array(BW)"
      ],
      "metadata": {
        "id": "g0TMn1mTr1LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_orig, _, train_BW, _ = train_test_split(Orig, BW, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FPPhmLG4wz7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_history = model.fit(train_BW, train_orig, epochs=15, verbose=1)"
      ],
      "metadata": {
        "id": "e_FpxKpGbakF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "h2ZQl5qLvSn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = []\n",
        "B = []\n",
        "for img in BW:\n",
        "  cartoon_rgb = model.predict(img)\n",
        "  #\n",
        "  cartoon_rgb = 1.0/255*cartoon_rgb\n",
        "  #\n",
        "  cartoon_lab = color.rgb2lab(cartoon_rgb)\n",
        "  a = cartoon_lab[:, :, 1]\n",
        "  b = cartoon_lab[:, :, 2]\n",
        "  A.append(a)\n",
        "  B.append(b)\n",
        "\n",
        "\n",
        "original_dir = '../content/test/'\n",
        "\n",
        "L = []\n",
        "for filename in listdir(training_dir):\n",
        "  data_rgb = img_to_array(load_img(original_dir+filename, target_size=(256,256)))\n",
        "  data_rgb = 1.0/255*data_rgb\n",
        "  data_lab = color.rgb2lab(data_rgb)\n",
        "  l = data_lab[:, :, 0]\n",
        "  L.append(l)"
      ],
      "metadata": {
        "id": "DPc0QreuUdtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_dir = '../content/results/'\n",
        "\n",
        "results = np.empty((len(L), 256, 256, 3))\n",
        "img = 0\n",
        "for filename in listdir(training_dir):\n",
        "  results[img,:,:,0] = L[img]\n",
        "  results[img,:,:,1] = A[img]\n",
        "  results[img,:,:,2] = B[img]\n",
        "  results[img,:,:,:] = color.lab2rgb(results[img,:,:,:])\n",
        "  io.imsave(results_dir+filename, results[img,:,:,:])\n",
        "  img += 1"
      ],
      "metadata": {
        "id": "ZUC1cvOXROT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r results.zip results"
      ],
      "metadata": {
        "id": "_dUCjLqxadM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"results.zip\")"
      ],
      "metadata": {
        "id": "B76uqphmaoXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. loading immagini originali e cartoon \n",
        "  - resized 256x256\n",
        "\n",
        "2. fittare su: \n",
        "  - input -> train cartoon BW\n",
        "  - target -> train cartoon orig\n",
        "\n",
        "3. testare su tutto dataset cartoon\n",
        "\n",
        "4. salva immagini cartoon ricolorate\n",
        "\n",
        "5. estrarre 'l' da immagini originali + 'ab' da immagini cartoon ricolorate\n",
        "\n",
        "6. salva immagini ottenute\n",
        "\n",
        "7. calcola metriche"
      ],
      "metadata": {
        "id": "GrmiR0xHvqFd"
      }
    }
  ]
}