{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "DemoChromaGAN_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.6 64-bit ('chromaGAN': virtualenv)"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "9019ed601c3bb39ceb63ab078ec9112e9e1727faf0e317e7f365960b792642c4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChromaGAN Demo\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook allows you to colorize your images using ChromaGAN. \n",
        "\n",
        "Basic instructions:\n",
        "0.   Set GPU (Edit > Notebook settings or Runtime > Change runtime type and select GPU as Hardware accelerator.)\n",
        "1.   To execute a cell you have to select the corresponding cell by clicking on it and then click on the play icon that appears at the left top corner of the code.\n",
        "2.   To replicate the results obtained in the paper ChromaGAN execute cell number 1.\n",
        "3.   To colorize your own images execute cells number 2.1 and 2.2 in order. The execution of a cell has to end before starting the execution of the following one.\n",
        "\n",
        "If you use this demo for your research, please cite our paper [ChromaGAN: Adversarial Picture Colorization with Semantic Class Distribution](https://openaccess.thecvf.com/content_WACV_2020/papers/Vitoria_ChromaGAN_Adversarial_Picture_Colorization_with_Semantic_Class_Distribution_WACV_2020_paper.pdf):\n",
        "\n",
        "```\n",
        "\n",
        "@inproceedings{vitoria2020chromagan,\n",
        "  title={ChromaGAN: Adversarial Picture Colorization with Semantic Class Distribution},\n",
        "  author={Vitoria, Patricia and Raad, Lara and Ballester, Coloma},\n",
        "  booktitle={The IEEE Winter Conference on Applications of Computer Vision},\n",
        "  pages={2445--2454},\n",
        "  year={2020}\n",
        "}\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7jaPdHaiS7-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Run demo on ChromaGAN images\n",
        "\n",
        "This first part runs ChromaGAN on the images used in our paper. The results will be saved in the folder chromagan_results/ and are also displayed one by one (left: grayscale image, center: colorized image, right: ground truth image) followed by the corresponding PSNR value."
      ],
      "metadata": {
        "id": "PFJfjYH2c-Wa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip uninstall h5py --yes\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "!pip install opencv-python==4.1.25\n",
        "!pip install numpy==1.15.4\n",
        "!pip install keras==2.2.4"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ChromaGAN\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from keras import applications\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# DIRECTORY INFORMATION\n",
        "DATA_DIR = os.path.join('../img/original/ImageNet')\n",
        "OUT_DIR = os.path.join('../img/colorized/chromagan/')\n",
        "MODEL_DIR = os.path.join('../models')\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "# TRAINING INFORMATION\n",
        "PRETRAINED = \"my_model_colorization.h5\" \n",
        "\n",
        "class DATA():\n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dir_path = dirname\n",
        "        self.folder_list = [folder for folder in listdir(DATA_DIR) if not isfile(join(DATA_DIR, folder))]\n",
        "        self.size = len(self.folder_list)\n",
        "        self.batch_size = BATCH_SIZE\n",
        "\n",
        "    def read_img(self, filename):\n",
        "        IMAGE_SIZE = 224\n",
        "        img = cv2.imread(filename, 3)\n",
        "        height, width, channels = img.shape\n",
        "        labimg = cv2.cvtColor(cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE)), cv2.COLOR_BGR2Lab)\n",
        "        labimg_ori = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
        "        return np.reshape(labimg[:,:,0], (IMAGE_SIZE, IMAGE_SIZE, 1)), labimg[:, :, 1:], img, np.reshape(labimg_ori[:,:,0], (height, width, 1))\n",
        "\n",
        "    def generate_batch(self):\n",
        "        batch = []\n",
        "        labels = []\n",
        "        filelist = []\n",
        "        labimg_oritList= []\n",
        "        originalList = [] \n",
        "        for i in range(self.batch_size):\n",
        "            for d in self.folder_list:\n",
        "                in_path = join(DATA_DIR, d)\n",
        "                out_path = join(OUT_DIR, d)\n",
        "                if not os.path.exists(out_path):\n",
        "                    os.makedirs(out_path)\n",
        "                onlyfiles = [f for f in listdir(in_path) if isfile(join(in_path, f))]\n",
        "                for f in onlyfiles:\n",
        "                    filename = os.path.join(in_path, f)\n",
        "                    filelist.append(filename)\n",
        "                    greyimg, colorimg, original, labimg_ori = self.read_img(filename)\n",
        "                    batch.append(greyimg)\n",
        "                    labels.append(colorimg)\n",
        "                    originalList.append(original)\n",
        "                    labimg_oritList.append(labimg_ori)\n",
        "        batch = np.asarray(batch)/255 # values between 0 and 1\n",
        "        labels = np.asarray(labels)/255 # values between 0 and 1\n",
        "        originalList = np.asarray(originalList)\n",
        "        labimg_oritList = np.asarray(labimg_oritList)/255\n",
        "        return batch, labels, filelist, originalList, labimg_oritList\n",
        "\n",
        "def deprocess(imgs):\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "def reconstruct(batchX, predictedY):\n",
        "    result = np.concatenate((batchX, predictedY), axis=2)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_Lab2BGR)\n",
        "         \n",
        "    return result\n",
        "\n",
        "def sample_images():\n",
        "    avg_ssim = 0\n",
        "    avg_psnr = 0\n",
        "    VGG_modelF = applications.vgg16.VGG16(weights='imagenet', include_top=True) \n",
        "    save_path = os.path.join(MODEL_DIR, PRETRAINED)\n",
        "    colorizationModel = load_model(save_path)\n",
        "    test_data = DATA(DATA_DIR)\n",
        "    assert test_data.size >= 0, \"Your list of images to colorize is empty. Please load images.\"\n",
        "    assert BATCH_SIZE<=test_data.size, \"The batch size (\" + str(BATCH_SIZE)+ \") should be smaller or equal to the number of testing images (\" + str(data_test.size)+ \") --> modify it\"\n",
        "    total_batch = int(test_data.size/BATCH_SIZE)\n",
        "    print(\"\")\n",
        "    print(\"number of images to colorize: \" + str(test_data.size))\n",
        "    print(\"total number of batches to colorize: \" + str(total_batch))\n",
        "    print(\"\")\n",
        "    if not os.path.exists(OUT_DIR):\n",
        "      print('created save result path')\n",
        "      os.makedirs(OUT_DIR)\n",
        "    for b in range(total_batch):\n",
        "            print(\"ok\")\n",
        "            batchX, batchY, filelist, original, labimg_oritList = test_data.generate_batch()\n",
        "            predY, _ = colorizationModel.predict(np.tile(batchX,[1,1,1,3]))\n",
        "            predictVGG =VGG_modelF.predict(np.tile(batchX,[1,1,1,3]))\n",
        "            loss = colorizationModel.evaluate(np.tile(batchX,[1,1,1,3]), [batchY, predictVGG], verbose=0)\n",
        "            for i in range(BATCH_SIZE):\n",
        "                print(\"ok2\")\n",
        "                originalResult = original[i]\n",
        "                height, width, channels = originalResult.shape\n",
        "                predY_2 = deprocess(predY[i])\n",
        "                predY_2 = cv2.resize(predY_2, (width,height))\n",
        "                labimg_oritList_2 =labimg_oritList[i]\n",
        "                print(\"ok3\")\n",
        "                predResult_2= reconstruct(deprocess(labimg_oritList_2), predY_2)\n",
        "                print(\"ok4\")\n",
        "                ssim= tf.keras.backend.eval( tf.image.ssim(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                psnr= tf.keras.backend.eval( tf.image.psnr(tf.convert_to_tensor(originalResult, dtype=tf.float32), tf.convert_to_tensor(predResult_2, dtype=tf.float32), max_val=255))\n",
        "                avg_ssim += ssim\n",
        "                avg_psnr += psnr\n",
        "                print(\"ok5\")\n",
        "\n",
        "                save_path = os.path.join(OUT_DIR, filelist[i][:-4] +\"_reconstructed.jpg\" )\n",
        "                print(save_path)\n",
        "                cv2.imwrite(save_path, predResult_2)\n",
        "                print(\"\")\n",
        "                print(\"Image \" + str(i+1) + \"/\" +str(BATCH_SIZE) + \" in batch \" + str(b+1) + \"/\" +str(total_batch) + \". From left to right: grayscale image to colorize, colorized image ( PSNR =\", \"{:.8f}\".format(psnr),\")\")\n",
        "                print(\"and ground truth image. Notice that PSNR has no sense in original black and white images.\")\n",
        "                print(\"\")\n",
        "                print(\"\")\n",
        "\n",
        "    print(\"average ssim loss =\", \"{:.8f}\".format(avg_ssim/(total_batch*BATCH_SIZE)))\n",
        "    print(\"average psnr loss =\", \"{:.8f}\".format(avg_psnr/(total_batch*BATCH_SIZE)))\n",
        "\n",
        "\n",
        "sample_images()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "Session cannot generate requests",
          "traceback": [
            "Error: Session cannot generate requests",
            "at w.executeCodeCell (/Users/chiarabigarella/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:301310)",
            "at w.execute (/Users/chiarabigarella/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:300703)",
            "at w.start (/Users/chiarabigarella/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:296367)",
            "at runMicrotasks (<anonymous>)",
            "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
            "at async t.CellExecutionQueue.executeQueuedCells (/Users/chiarabigarella/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:311160)",
            "at async t.CellExecutionQueue.start (/Users/chiarabigarella/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:310700)"
          ]
        }
      ],
      "metadata": {
        "id": "pn0KNolEdDf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3998a6a-03c3-45a4-845c-454cdff5a48b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Run demo on uploaded images\n",
        "\n",
        "This second part runs ChromaGAN on your selected images.\n",
        "\n",
        "## 2.1 Load images\n",
        "\n",
        "You can manually upload images from your computer. They can either be black and white images or color images. In the latter, the images are first transformed to their grayscale version and then colorized. \n",
        "\n",
        "Uploading images: first click on the folder icon located on the left. This will deploy the folders and files of the current directory. On top you'll find the upload icon that will allow you to upload all your images. These uploaded images will appear in your working directory and will later be automatically moved to the folder sample_images/.\n",
        "\n",
        "You can also directly download images from the web. For that, you have to add in the code cell below the following code line for each image to download:\n",
        "\n",
        "```\n",
        "!wget image_url\n",
        "```\n",
        "\n",
        "These images will also be saved in the current directory and will later be automatically moved to the folder sample_images/.\n",
        "\n",
        "An example for uploading one image from the web (replace this line by the lines corresponding to the images you want to download):"
      ],
      "metadata": {
        "id": "fCIKt79VoYug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Charlie_Chaplin.jpg/1024px-Charlie_Chaplin.jpg"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dyld: Library not loaded: /usr/local/opt/openssl/lib/libssl.1.0.0.dylib\n",
            "  Referenced from: /usr/local/bin/wget\n",
            "  Reason: image not found\n"
          ]
        }
      ],
      "metadata": {
        "id": "uYolNxuUNMFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Run demo\n",
        "\n",
        "The results will be saved in the folder sample_results/ and are displayed one by one (left: grayscale image, center: colorized image, right: ground truth image) followed by its PSNR value. In the case of a black and white images the PSNR value has no sense since we do not have the ground truth color version to compare with."
      ],
      "metadata": {
        "id": "BoatxJSRjYwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dyld: Library not loaded: /usr/local/opt/openssl/lib/libssl.1.0.0.dylib\n",
            "  Referenced from: /usr/local/bin/wget\n",
            "  Reason: image not found\n",
            "/bin/bash: line 1: 40396 Abort trap: 6           wget http://dev.ipol.im/~lraad/chromaGAN/model/my_model_colorization.h5\n",
            "mv: rename my_model_colorization.h5 to MODEL/my_model_colorization.h5: No such file or directory\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}